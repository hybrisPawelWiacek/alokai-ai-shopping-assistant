# ===============================================
# Alokai Storefront Configuration
# ===============================================

# Middleware Configuration
NEXT_PUBLIC_ALOKAI_MIDDLEWARE_API_URL="http://localhost:4000"

# For CDN cache busting, you can use a hash or a version number. By default, deployed version
# uses the git commit hash. For local development, you can use a random string or skip it.
#NEXT_PUBLIC_ALOKAI_MIDDLEWARE_CDN_CACHE_BUSTING_ID="example-hash"

# Multistore Configuration
NEXT_PUBLIC_ALOKAI_MULTISTORE_ENABLED=false

# Image Optimization
# Default Image Loader fetch url.
# For Cloudinary check https://cloudinary.com/documentation/fetch_remote_images#fetch_and_deliver_remote_files
NEXT_PUBLIC_IMAGE_LOADER_FETCH_URL=https://res.cloudinary.com/vsf-sap/image/fetch/
# Optional. Will be used when image url will not start with http.
# For Cloudinary check https://cloudinary.com/documentation/migration#lazy_migration_with_auto_upload
NEXT_PUBLIC_IMAGE_LOADER_UPLOAD_URL=https://res.cloudinary.com/vsf-sap/image/upload/

# CDN Cache Control
# Default value for the Cache-Control header for the CDN cacheable pages.
# See https://docs.alokai.com/storefront/features/cdn/making-ssr-cacheable
NEXT_DEFAULT_HTML_CACHE_CONTROL="public, max-age=0, s-maxage=15, must-revalidate"

# ===============================================
# AI Shopping Assistant Configuration
# ===============================================
# ⚠️ SECURITY WARNING: These are server-side variables!
# NEVER prefix these with NEXT_PUBLIC_ as that would expose them to the client.
# These keys should only be accessible in server-side code (API routes, server components).

# OpenAI Configuration (Required for AI Assistant)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here
# Model selection - Options: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
OPENAI_MODEL=gpt-4-turbo-preview

# Optional: Alternative LLM Providers
# Uncomment to use Anthropic Claude instead of OpenAI
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-opus-20240229

# AI Assistant Behavior Configuration
# Temperature controls randomness (0.0 = deterministic, 1.0 = creative)
AI_ASSISTANT_TEMPERATURE=0.7
# Maximum tokens in AI responses
AI_ASSISTANT_MAX_TOKENS=2000
# Request timeout in milliseconds
AI_ASSISTANT_TIMEOUT_MS=30000

# Rate Limiting Configuration
# Requests per minute for regular users
AI_ASSISTANT_RATE_LIMIT=60
# Requests per minute for B2B users (higher limit)
AI_ASSISTANT_RATE_LIMIT_B2B=120

# ===============================================
# Observability & Monitoring (Optional)
# ===============================================

# OpenTelemetry Configuration
# Enable distributed tracing for performance monitoring
OPENTELEMETRY_ENABLED=false
# OpenTelemetry collector endpoint
OPENTELEMETRY_ENDPOINT=http://localhost:4318
# Service name for tracing
OPENTELEMETRY_SERVICE_NAME=ai-shopping-assistant

# Logging Configuration
# Options: error, warn, info, debug
LOG_LEVEL=info

# ===============================================
# Performance & Caching (Optional)
# ===============================================

# AI Response Caching
# Cache TTL in seconds (5 minutes default)
AI_ASSISTANT_CACHE_TTL=300
# Maximum number of cached responses
AI_ASSISTANT_CACHE_MAX_SIZE=100

# ===============================================
# Security & Compliance (Optional)
# ===============================================

# Content moderation
# Enable to filter inappropriate content
AI_ASSISTANT_CONTENT_MODERATION=true

# Audit logging
# Enable to log all AI interactions for compliance
AI_ASSISTANT_AUDIT_LOGGING=false
# Audit log retention in days
AI_ASSISTANT_AUDIT_RETENTION_DAYS=90
